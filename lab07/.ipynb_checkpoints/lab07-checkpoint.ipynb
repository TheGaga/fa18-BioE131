{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab07 \n",
    "- Determining which compression algorithm will generate the most savings\n",
    "- The algorithm you choose must either:\n",
    "    - be quick enough to compress 1000 terabytes a day\n",
    "    - efficient enough that even if all the data isn’t compressed, the savings are maximized by the data that you\n",
    "        have time to compress."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: writing some code to simulate files containing random DNA, protein, and binary data\n",
    "- Using np.random.choice, generate 100 megabytes (8 bits/byte * 1024 bytes/kilobyte * 1024 kilobytes/megabyte * 100) of random data containing 100%, 90%, 80%, 70%, 60%, and 50% zeros. Be sure to call np.packbits on your data before writing it to a file.\n",
    "- Then write this data to a file in your home directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# define a function for writing random bit  file\n",
    "def write_random_bits(file_name,percent_zero):\n",
    "    bit_length = 8 * 1024 * 1024 * 100\n",
    "    myvar = np.random.choice([0, 1], size = bit_length, replace = True, p = [percent_zero, 1-percent_zero])\n",
    "    s = np.packbits(myvar)\n",
    "    open(file_name, \"wb\").write(s)\n",
    "\n",
    "#100%\n",
    "write_random_bits(\"./zeros_100p\",1)\n",
    "# #90%\n",
    "write_random_bits(\"./zeros_90p\",0.9)\n",
    "# #80%\n",
    "write_random_bits(\"./zeros_80p\",0.8)\n",
    "# #70%\n",
    "write_random_bits(\"./zeros_70p\",0.7)\n",
    "# #60%\n",
    "write_random_bits(\"./zeros_60p\",0.6)\n",
    "# #50%\n",
    "write_random_bits(\"./zeros_50p\",0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Next, generate DNA and protein sequences 100 million letters long and write those to your home directory. The probability of each letter should be equal. To write strings generated in Numpy to a file, you’ll have to use a slightly different command, like this: `open(“nt_seq.fa”, “w”).write(“”.join(my_nt_seq))`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def write_random_nt(file_name):\n",
    "    nt_length = 100000000\n",
    "    my_nt_seq = np.random.choice([\"A\",\"G\",\"C\",\"T\"], size = nt_length, replace = True, p = [0.25,0.25,0.25,0.25])\n",
    "    open(file_name, \"w\").write(\"\".join(my_nt_seq))\n",
    "\n",
    "write_random_nt(\"nt_seq.fa\")\n",
    "\n",
    "def write_random_aa(file_name):\n",
    "    aa_length = 100000000\n",
    "    my_aa_seq = np.random.choice(['C', 'D', 'S', 'Q', 'K', 'I', 'P', 'T', 'F', 'N', 'G', 'H', 'L', 'R', 'W', 'A','V','E', 'Y','M'], size = aa_length, replace = True, p = [0.05]*20)\n",
    "    open(file_name, \"w\").write(\"\".join(my_aa_seq))\n",
    "\n",
    "write_random_aa(\"aa_seq.fa\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compressing the data\n",
    "- On each of the files you generated above, run gzip, bzip, pbzip2 and ArithmeticCompress as follows:\n",
    "- `time gzip –k zeros_100p`\n",
    "- `time bzip2 –k zeros_100p`\n",
    "- `time pbzip2 –k zeros_100p`\n",
    "- `time ArithmeticCompress zeros_100p zeros_100p.art`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zeros_100p\n",
      "0.70user 0.03system 0:00.73elapsed 99%CPU (0avgtext+0avgdata 1864maxresident)k\n",
      "0inputs+200outputs (0major+146minor)pagefaults 0swaps\n",
      "\n",
      "0.99user 0.03system 0:01.03elapsed 99%CPU (0avgtext+0avgdata 8880maxresident)k\n",
      "0inputs+8outputs (0major+1903minor)pagefaults 0swaps\n",
      "\n",
      "1.52user 0.16system 0:00.35elapsed 475%CPU (0avgtext+0avgdata 15728maxresident)k\n",
      "204808inputs+16outputs (0major+14405minor)pagefaults 0swaps\n",
      "\n",
      "14.89user 0.02system 0:14.91elapsed 99%CPU (0avgtext+0avgdata 4300maxresident)k\n",
      "0inputs+8outputs (0major+234minor)pagefaults 0swaps\n",
      "\n",
      "zeros_90p\n",
      "19.06user 0.12system 0:19.19elapsed 99%CPU (0avgtext+0avgdata 1824maxresident)k\n",
      "0inputs+114720outputs (0major+217minor)pagefaults 0swaps\n",
      "\n",
      "10.59user 0.06system 0:10.65elapsed 99%CPU (0avgtext+0avgdata 7768maxresident)k\n",
      "0inputs+119464outputs (0major+1691minor)pagefaults 0swaps\n",
      "\n",
      "17.99user 0.64system 0:00.72elapsed 2557%CPU (0avgtext+0avgdata 283508maxresident)k\n",
      "204800inputs+119512outputs (0major+221542minor)pagefaults 0swaps\n",
      "\n",
      "28.68user 0.24system 0:28.92elapsed 100%CPU (0avgtext+0avgdata 4180maxresident)k\n",
      "0inputs+96056outputs (0major+232minor)pagefaults 0swaps\n",
      "\n",
      "zeros_80p\n",
      "13.17user 0.13system 0:13.31elapsed 99%CPU (0avgtext+0avgdata 1768maxresident)k\n",
      "0inputs+158520outputs (0major+207minor)pagefaults 0swaps\n",
      "\n",
      "12.33user 0.14system 0:12.48elapsed 99%CPU (0avgtext+0avgdata 7824maxresident)k\n",
      "0inputs+169232outputs (0major+1692minor)pagefaults 0swaps\n",
      "\n",
      "22.68user 0.71system 0:00.89elapsed 2602%CPU (0avgtext+0avgdata 287676maxresident)k\n",
      "204808inputs+169256outputs (0major+227769minor)pagefaults 0swaps\n",
      "\n",
      "35.30user 0.26system 0:35.57elapsed 99%CPU (0avgtext+0avgdata 4376maxresident)k\n",
      "0inputs+147848outputs (0major+237minor)pagefaults 0swaps\n",
      "\n",
      "zeros_70p\n",
      "5.91user 0.07system 0:05.99elapsed 99%CPU (0avgtext+0avgdata 1776maxresident)k\n",
      "0inputs+182856outputs (0major+202minor)pagefaults 0swaps\n",
      "\n",
      "13.60user 0.11system 0:13.72elapsed 99%CPU (0avgtext+0avgdata 7744maxresident)k\n",
      "0inputs+194856outputs (0major+1689minor)pagefaults 0swaps\n",
      "\n",
      "28.17user 0.62system 0:01.09elapsed 2620%CPU (0avgtext+0avgdata 285316maxresident)k\n",
      "204800inputs+194864outputs (0major+236187minor)pagefaults 0swaps\n",
      "\n",
      "39.15user 0.31system 0:39.48elapsed 99%CPU (0avgtext+0avgdata 4172maxresident)k\n",
      "0inputs+180496outputs (0major+231minor)pagefaults 0swaps\n",
      "\n",
      "zeros_60p\n",
      "4.14user 0.09system 0:04.24elapsed 99%CPU (0avgtext+0avgdata 1808maxresident)k\n",
      "0inputs+200040outputs (0major+206minor)pagefaults 0swaps\n",
      "\n",
      "15.56user 0.18system 0:15.74elapsed 100%CPU (0avgtext+0avgdata 7768maxresident)k\n",
      "0inputs+204904outputs (0major+1693minor)pagefaults 0swaps\n",
      "\n",
      "33.66user 0.67system 0:01.25elapsed 2744%CPU (0avgtext+0avgdata 287940maxresident)k\n",
      "204808inputs+204920outputs (0major+259528minor)pagefaults 0swaps\n",
      "\n",
      "41.22user 0.44system 0:41.67elapsed 99%CPU (0avgtext+0avgdata 4300maxresident)k\n",
      "0inputs+198856outputs (0major+233minor)pagefaults 0swaps\n",
      "\n",
      "zeros_50p\n",
      "3.53user 0.23system 0:03.76elapsed 100%CPU (0avgtext+0avgdata 1780maxresident)k\n",
      "0inputs+204840outputs (0major+128minor)pagefaults 0swaps\n",
      "\n",
      "17.32user 0.17system 0:17.50elapsed 100%CPU (0avgtext+0avgdata 7720maxresident)k\n",
      "0inputs+205696outputs (0major+1691minor)pagefaults 0swaps\n",
      "\n",
      "36.95user 0.71system 0:01.36elapsed 2759%CPU (0avgtext+0avgdata 290248maxresident)k\n",
      "204808inputs+205728outputs (0major+268890minor)pagefaults 0swaps\n",
      "\n",
      "40.42user 0.33system 0:40.76elapsed 99%CPU (0avgtext+0avgdata 4344maxresident)k\n",
      "0inputs+204808outputs (0major+236minor)pagefaults 0swaps\n",
      "\n",
      "nt_seq.fa\n",
      "12.03user 0.09system 0:12.13elapsed 99%CPU (0avgtext+0avgdata 1828maxresident)k\n",
      "195320inputs+57080outputs (0major+227minor)pagefaults 0swaps\n",
      "\n",
      "9.39user 0.03system 0:09.43elapsed 99%CPU (0avgtext+0avgdata 7716maxresident)k\n",
      "0inputs+53392outputs (0major+1691minor)pagefaults 0swaps\n",
      "\n",
      "15.41user 0.57system 0:00.63elapsed 2509%CPU (0avgtext+0avgdata 271300maxresident)k\n",
      "195328inputs+53408outputs (0major+206243minor)pagefaults 0swaps\n",
      "\n",
      "21.17user 0.20system 0:21.38elapsed 99%CPU (0avgtext+0avgdata 4224maxresident)k\n",
      "0inputs+48832outputs (0major+234minor)pagefaults 0swaps\n",
      "\n",
      "aa_seq.fa\n",
      "4.18user 0.08system 0:04.27elapsed 99%CPU (0avgtext+0avgdata 1824maxresident)k\n",
      "0inputs+118280outputs (0major+217minor)pagefaults 0swaps\n",
      "\n",
      "9.87user 0.07system 0:09.94elapsed 100%CPU (0avgtext+0avgdata 7700maxresident)k\n",
      "0inputs+107920outputs (0major+1689minor)pagefaults 0swaps\n",
      "\n",
      "18.80user 0.77system 0:00.77elapsed 2517%CPU (0avgtext+0avgdata 269264maxresident)k\n",
      "0inputs+107952outputs (0major+213383minor)pagefaults 0swaps\n",
      "\n",
      "28.42user 0.24system 0:28.66elapsed 100%CPU (0avgtext+0avgdata 4308maxresident)k\n",
      "0inputs+105520outputs (0major+234minor)pagefaults 0swaps\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "import pandas as pd\n",
    "file_names = [\"zeros_100p\",\"zeros_90p\",\"zeros_80p\",\"zeros_70p\",\"zeros_60p\",\"zeros_50p\",\"nt_seq.fa\",\"aa_seq.fa\"]\n",
    "gzip_time = []\n",
    "bzip_time = []\n",
    "pbzip_time = []\n",
    "arith_time = []\n",
    "\n",
    "for file_name in file_names:\n",
    "    print(file_name)\n",
    "    arith_out_name = file_name + \".art\"\n",
    "    pdbzip_name = file_name+ \"b\"\n",
    "    p1 = subprocess.run(['time', 'gzip', '-k', file_name], stdout=subprocess.PIPE, stderr= subprocess.PIPE)\n",
    "    out1 = p1.stderr.decode()\n",
    "    print(out1)\n",
    "    gzip_time.append(str(out1))\n",
    "    p2 = subprocess.run(['time', 'bzip2', '-k', file_name], stdout=subprocess.PIPE, stderr= subprocess.PIPE)\n",
    "    out2 = p2.stderr.decode()\n",
    "    print(out2)\n",
    "    bzip_time.append(str(out2))\n",
    "    p3 = subprocess.run(['time', 'pbzip2', '-k', pdbzip_name], stdout=subprocess.PIPE, stderr= subprocess.PIPE)\n",
    "    out3 = p3.stderr.decode()\n",
    "    print(out3)\n",
    "    pbzip_time.append(str(out3))\n",
    "    p4 = subprocess.run(['time',\"ArithmeticCompress\",file_name,arith_out_name], stdout=subprocess.PIPE, stderr= subprocess.PIPE)\n",
    "    out4 = p4.stderr.decode()\n",
    "    print(out4)\n",
    "    arith_time.append(str(out4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "gzip_time = [elem.split(\" \")[2] for elem in gzip_time]\n",
    "bzip_time = [elem.split(\" \")[2] for elem in bzip_time]\n",
    "pbzip_time = [elem.split(\" \")[2] for elem in pbzip_time]\n",
    "arith_time = [elem.split(\" \")[2] for elem in arith_time]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "gzip_time = [elem[0:7] for elem in gzip_time]\n",
    "bzip_time = [elem[0:7] for elem in bzip_time]\n",
    "pbzip_time = [elem[0:7] for elem in pbzip_time]\n",
    "arith_time = [elem[0:7] for elem in arith_time]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0:00.73', '0:19.19', '0:13.31', '0:05.99', '0:04.24', '0:03.76', '0:12.13', '0:04.27']\n",
      "['0:01.03', '0:10.65', '0:12.48', '0:13.72', '0:15.74', '0:17.50', '0:09.43', '0:09.94']\n",
      "['0:00.35', '0:00.72', '0:00.89', '0:01.09', '0:01.25', '0:01.36', '0:00.63', '0:00.77']\n",
      "['0:14.91', '0:28.92', '0:35.57', '0:39.48', '0:41.67', '0:40.76', '0:21.38', '0:28.66']\n"
     ]
    }
   ],
   "source": [
    "print(gzip_time)\n",
    "print(bzip_time )\n",
    "print(pbzip_time )\n",
    "print(arith_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have the compression time and the output, fetch the size of the original and the output file through a subprocess run "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "zeros_100p:\n",
      "101802\n",
      "113\n",
      "5615\n",
      "1028\n",
      "104857600\n",
      "\n",
      "zeros_90p:\n",
      "58735562\n",
      "61163710\n",
      "61186861\n",
      "49179282\n",
      "104857600\n",
      "\n",
      "zeros_80p:\n",
      "81158774\n",
      "86644358\n",
      "86657539\n",
      "75697439\n",
      "104857600\n",
      "\n",
      "zeros_70p:\n",
      "93619496\n",
      "99762929\n",
      "99769104\n",
      "92412928\n",
      "104857600\n",
      "\n",
      "zeros_60p:\n",
      "102418195\n",
      "104910826\n",
      "104917515\n",
      "101812051\n",
      "104857600\n",
      "\n",
      "zeros_50p:\n",
      "104874331\n",
      "105313629\n",
      "105328728\n",
      "104858604\n",
      "104857600\n",
      "\n",
      "nt_seq.fa:\n",
      "29222351\n",
      "27334634\n",
      "27342473\n",
      "25001028\n",
      "100000000\n",
      "\n",
      "aa_seq.fa:\n",
      "60559282\n",
      "55254152\n",
      "55268511\n",
      "54025126\n",
      "100000000\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "import pandas as pd\n",
    "file_names = [\"zeros_100p\",\"zeros_90p\",\"zeros_80p\",\"zeros_70p\",\"zeros_60p\",\"zeros_50p\",\"nt_seq.fa\",\"aa_seq.fa\"]\n",
    "original_size = []\n",
    "gzip_size = []\n",
    "bzip_size = []\n",
    "pbzip_size = []\n",
    "arith_size = []\n",
    "\n",
    "for file_name in file_names:\n",
    "    print(\"\\n\" + file_name + \":\")\n",
    "    arith_out_name = file_name + \".art\"\n",
    "    bzip_name = file_name+ \".bz2\"\n",
    "    pbzip_name = file_name+ \"b.bz2\"\n",
    "    gzip_name = file_name+ \".gz\"\n",
    "    \n",
    "    p1 = subprocess.run(['stat', '--printf=%s', gzip_name], stdout=subprocess.PIPE, stderr= subprocess.PIPE)\n",
    "    out1 = p1.stdout.decode()\n",
    "    print(out1)\n",
    "    gzip_size.append(str(out1))\n",
    "    \n",
    "    p2 = subprocess.run(['stat', '--printf=%s', bzip_name], stdout=subprocess.PIPE, stderr= subprocess.PIPE)\n",
    "    out2 = p2.stdout.decode()\n",
    "    print(out2)\n",
    "    bzip_size.append(str(out2))\n",
    "    \n",
    "    p3 = subprocess.run(['stat', '--printf=%s', pbzip_name], stdout=subprocess.PIPE, stderr= subprocess.PIPE)\n",
    "    out3 = p3.stdout.decode()\n",
    "    print(out3)\n",
    "    pbzip_size.append(str(out3))\n",
    "    \n",
    "    p4 = subprocess.run(['stat', '--printf=%s', arith_out_name], stdout=subprocess.PIPE, stderr= subprocess.PIPE)\n",
    "    out4 = p4.stdout.decode()\n",
    "    print(out4)\n",
    "    arith_size.append(str(out4))\n",
    "    \n",
    "    p5 = subprocess.run(['stat', '--printf=%s', file_name], stdout=subprocess.PIPE, stderr= subprocess.PIPE)\n",
    "    out5 = p5.stdout.decode()\n",
    "    print(out5)\n",
    "    original_size.append(str(out5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['104857600', '104857600', '104857600', '104857600', '104857600', '104857600', '100000000', '100000000']\n",
      "['101802', '58735562', '81158774', '93619496', '102418195', '104874331', '29222351', '60559282']\n",
      "['113', '61163710', '86644358', '99762929', '104910826', '105313629', '27334634', '55254152']\n",
      "['5615', '61186861', '86657539', '99769104', '104917515', '105328728', '27342473', '55268511']\n",
      "['1028', '49179282', '75697439', '92412928', '101812051', '104858604', '25001028', '54025126']\n"
     ]
    }
   ],
   "source": [
    "print(original_size)\n",
    "print(gzip_size)\n",
    "print(bzip_size)\n",
    "print(pbzip_size)\n",
    "print(arith_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>original_size</th>\n",
       "      <th>gzip_size</th>\n",
       "      <th>bzip_size</th>\n",
       "      <th>pbzip_size</th>\n",
       "      <th>arith_size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>zeros_100p</td>\n",
       "      <td>104857600</td>\n",
       "      <td>101802</td>\n",
       "      <td>113</td>\n",
       "      <td>5615</td>\n",
       "      <td>1028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>zeros_90p</td>\n",
       "      <td>104857600</td>\n",
       "      <td>58735562</td>\n",
       "      <td>61163710</td>\n",
       "      <td>61186861</td>\n",
       "      <td>49179282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>zeros_80p</td>\n",
       "      <td>104857600</td>\n",
       "      <td>81158774</td>\n",
       "      <td>86644358</td>\n",
       "      <td>86657539</td>\n",
       "      <td>75697439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>zeros_70p</td>\n",
       "      <td>104857600</td>\n",
       "      <td>93619496</td>\n",
       "      <td>99762929</td>\n",
       "      <td>99769104</td>\n",
       "      <td>92412928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>zeros_60p</td>\n",
       "      <td>104857600</td>\n",
       "      <td>102418195</td>\n",
       "      <td>104910826</td>\n",
       "      <td>104917515</td>\n",
       "      <td>101812051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>zeros_50p</td>\n",
       "      <td>104857600</td>\n",
       "      <td>104874331</td>\n",
       "      <td>105313629</td>\n",
       "      <td>105328728</td>\n",
       "      <td>104858604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>nt_seq.fa</td>\n",
       "      <td>100000000</td>\n",
       "      <td>29222351</td>\n",
       "      <td>27334634</td>\n",
       "      <td>27342473</td>\n",
       "      <td>25001028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>aa_seq.fa</td>\n",
       "      <td>100000000</td>\n",
       "      <td>60559282</td>\n",
       "      <td>55254152</td>\n",
       "      <td>55268511</td>\n",
       "      <td>54025126</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     filename original_size  gzip_size  bzip_size pbzip_size arith_size\n",
       "0  zeros_100p     104857600     101802        113       5615       1028\n",
       "1   zeros_90p     104857600   58735562   61163710   61186861   49179282\n",
       "2   zeros_80p     104857600   81158774   86644358   86657539   75697439\n",
       "3   zeros_70p     104857600   93619496   99762929   99769104   92412928\n",
       "4   zeros_60p     104857600  102418195  104910826  104917515  101812051\n",
       "5   zeros_50p     104857600  104874331  105313629  105328728  104858604\n",
       "6   nt_seq.fa     100000000   29222351   27334634   27342473   25001028\n",
       "7   aa_seq.fa     100000000   60559282   55254152   55268511   54025126"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "d = {'filename': file_names, 'original_size': original_size,'gzip_size':gzip_size,'bzip_size':bzip_size, 'pbzip_size':pbzip_size,'arith_size':arith_size}\n",
    "df = pd.DataFrame(data=d)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>original_size</th>\n",
       "      <th>gzip_ratio</th>\n",
       "      <th>bzip_ratio</th>\n",
       "      <th>pbzip_ratio</th>\n",
       "      <th>arith_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>zeros_100p</td>\n",
       "      <td>104857600</td>\n",
       "      <td>0.000971</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000054</td>\n",
       "      <td>0.000010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>zeros_90p</td>\n",
       "      <td>104857600</td>\n",
       "      <td>0.560146</td>\n",
       "      <td>0.583303</td>\n",
       "      <td>0.583523</td>\n",
       "      <td>0.469010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>zeros_80p</td>\n",
       "      <td>104857600</td>\n",
       "      <td>0.773990</td>\n",
       "      <td>0.826305</td>\n",
       "      <td>0.826431</td>\n",
       "      <td>0.721907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>zeros_70p</td>\n",
       "      <td>104857600</td>\n",
       "      <td>0.892825</td>\n",
       "      <td>0.951413</td>\n",
       "      <td>0.951472</td>\n",
       "      <td>0.881318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>zeros_60p</td>\n",
       "      <td>104857600</td>\n",
       "      <td>0.976736</td>\n",
       "      <td>1.000508</td>\n",
       "      <td>1.000571</td>\n",
       "      <td>0.970955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>zeros_50p</td>\n",
       "      <td>104857600</td>\n",
       "      <td>1.000160</td>\n",
       "      <td>1.004349</td>\n",
       "      <td>1.004493</td>\n",
       "      <td>1.000010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>nt_seq.fa</td>\n",
       "      <td>100000000</td>\n",
       "      <td>0.292224</td>\n",
       "      <td>0.273346</td>\n",
       "      <td>0.273425</td>\n",
       "      <td>0.250010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>aa_seq.fa</td>\n",
       "      <td>100000000</td>\n",
       "      <td>0.605593</td>\n",
       "      <td>0.552542</td>\n",
       "      <td>0.552685</td>\n",
       "      <td>0.540251</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     filename original_size  gzip_ratio  bzip_ratio  pbzip_ratio  arith_ratio\n",
       "0  zeros_100p     104857600    0.000971    0.000001     0.000054     0.000010\n",
       "1   zeros_90p     104857600    0.560146    0.583303     0.583523     0.469010\n",
       "2   zeros_80p     104857600    0.773990    0.826305     0.826431     0.721907\n",
       "3   zeros_70p     104857600    0.892825    0.951413     0.951472     0.881318\n",
       "4   zeros_60p     104857600    0.976736    1.000508     1.000571     0.970955\n",
       "5   zeros_50p     104857600    1.000160    1.004349     1.004493     1.000010\n",
       "6   nt_seq.fa     100000000    0.292224    0.273346     0.273425     0.250010\n",
       "7   aa_seq.fa     100000000    0.605593    0.552542     0.552685     0.540251"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "gzip_ratio = np.divide([int(i) for i in gzip_size], [int(i) for i in original_size])\n",
    "bzip_ratio = np.divide([int(i) for i in bzip_size], [int(i) for i in original_size])\n",
    "pbzip_ratio = np.divide([int(i) for i in pbzip_size], [int(i) for i in original_size])\n",
    "arith_ratio = np.divide([int(i) for i in arith_size], [int(i) for i in original_size])\n",
    "\n",
    "d = {'filename': file_names, 'original_size': original_size,'gzip_ratio':gzip_ratio,'bzip_ratio':bzip_ratio, 'pbzip_ratio':pbzip_ratio,'arith_ratio':arith_ratio}\n",
    "df = pd.DataFrame(data=d)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>gzip_time</th>\n",
       "      <th>bzip_time</th>\n",
       "      <th>pbzip_time</th>\n",
       "      <th>arith_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>zeros_100p</td>\n",
       "      <td>0:00.73</td>\n",
       "      <td>0:01.03</td>\n",
       "      <td>0:00.35</td>\n",
       "      <td>0:14.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>zeros_90p</td>\n",
       "      <td>0:19.19</td>\n",
       "      <td>0:10.65</td>\n",
       "      <td>0:00.72</td>\n",
       "      <td>0:28.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>zeros_80p</td>\n",
       "      <td>0:13.31</td>\n",
       "      <td>0:12.48</td>\n",
       "      <td>0:00.89</td>\n",
       "      <td>0:35.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>zeros_70p</td>\n",
       "      <td>0:05.99</td>\n",
       "      <td>0:13.72</td>\n",
       "      <td>0:01.09</td>\n",
       "      <td>0:39.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>zeros_60p</td>\n",
       "      <td>0:04.24</td>\n",
       "      <td>0:15.74</td>\n",
       "      <td>0:01.25</td>\n",
       "      <td>0:41.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>zeros_50p</td>\n",
       "      <td>0:03.76</td>\n",
       "      <td>0:17.50</td>\n",
       "      <td>0:01.36</td>\n",
       "      <td>0:40.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>nt_seq.fa</td>\n",
       "      <td>0:12.13</td>\n",
       "      <td>0:09.43</td>\n",
       "      <td>0:00.63</td>\n",
       "      <td>0:21.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>aa_seq.fa</td>\n",
       "      <td>0:04.27</td>\n",
       "      <td>0:09.94</td>\n",
       "      <td>0:00.77</td>\n",
       "      <td>0:28.66</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     filename gzip_time bzip_time pbzip_time arith_time\n",
       "0  zeros_100p   0:00.73   0:01.03    0:00.35    0:14.91\n",
       "1   zeros_90p   0:19.19   0:10.65    0:00.72    0:28.92\n",
       "2   zeros_80p   0:13.31   0:12.48    0:00.89    0:35.57\n",
       "3   zeros_70p   0:05.99   0:13.72    0:01.09    0:39.48\n",
       "4   zeros_60p   0:04.24   0:15.74    0:01.25    0:41.67\n",
       "5   zeros_50p   0:03.76   0:17.50    0:01.36    0:40.76\n",
       "6   nt_seq.fa   0:12.13   0:09.43    0:00.63    0:21.38\n",
       "7   aa_seq.fa   0:04.27   0:09.94    0:00.77    0:28.66"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "d = {'filename': file_names, 'gzip_time':gzip_time,'bzip_time':bzip_time,'pbzip_time':pbzip_time,'arith_time':arith_time}\n",
    "df = pd.DataFrame(data=d)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Questions (Unfinished):  \n",
    "\n",
    "Which algorithm achieves the best level of compression on each file type?  \n",
    "- zeros_100p\": bzip\n",
    "- \"zeros_90p\": arith\n",
    "- \"zeros_80p\": arith\n",
    "- \"zeros_70p\": arith\n",
    "- \"zeros_60p\": arith\n",
    "- \"zeros_50p\": arith\n",
    "- \"nt_seq.fa: arith\n",
    "\n",
    "Which algorithm is the fastest?  \n",
    "- pbzip is the fastest\n",
    "What is the difference between bzip2 and pbzip2?   \n",
    "- pbzip2 is a parallel implementation of the bzip2 block-sorting file compressor that uses pthreads and achieves near-linear speedup on SMP machines.bzip2 performance is asymmetric, as decompression is relatively fast. Motivated by the large CPU time required for compression, a modified version was created in 2003 called pbzip2 that supported multi-threading, giving almost linear speed improvements on multi-CPU and multi-core computers.   \n",
    "\n",
    "Do you expect one to be faster and why?  \n",
    "- As pbzip2 uses more threads in parallel, it should work faster  \n",
    "\n",
    "How does the level of compression change as the percentage of zeros increases?  \n",
    "- as the percentage of zero increases, the compression works more efficiently and the compressed file to original file size ratio get smaller. \n",
    "\n",
    "Why does this happen?  \n",
    "According to the Shannon Entropy Calculation, the measure should be maximal if all the outcomes are equally likely, and as the outcome of 0/1 is more biased, it can be encoded with a more efficient coding algorithm due to the rucurring repeats and/or some characters occur much more frequently than other ones.\n",
    "\n",
    "What is the minimum number of bits required to store a single DNA base?  \n",
    "log2(4) = 2 bits  \n",
    "\n",
    "What is the minimum number of bits requiredto store an amino acid letter?   \n",
    "log2(20) = 4.321928  \n",
    "\n",
    "In your tests, how many bits did gzip and bzip2 actually require to store your random DNA and protein sequences?  \n",
    "DNA with gzip (bits):  \n",
    "29222351\t  \n",
    "DNA with bzip (bits):  \n",
    "27334634  \n",
    "protein with gzip (bits):  \n",
    "60559282\t\n",
    "protein with bzip (bits):  \n",
    "55254152  \n",
    "\n",
    "Are gzip and bzip2 performing well on DNA and proteins?  \n",
    "They are performing well on both, with a better efficiency on DNA around 0.3 and a less compression efficiency of ~0.6 compressed/original ratio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making gp120.fa file\n",
    "1. Human immunodeficiency virus 1 partial gp120 from EMBL database \n",
    "2. BLASTn the sequence to get homologs from other isolates :\n",
    "    - ENA|AAC98589|AAC98589.1  \n",
    "    - ENA|AF038095|AF038095.1  \n",
    "    - EU178169.1  \n",
    "    - KP109481.1  \n",
    "    - KC863161.1  \n",
    "    - JQ754299.1  \n",
    "    - KF374025.1  \n",
    "    - GU329320.1  \n",
    "    - HQ326124.1  \n",
    "    - HQ700003.1  \n",
    "3. copy the fasta sequence into the gp120.fas in the local desktop directory then\n",
    "    `scp /Users/changhua/desktop/gp120.fa be131-01@bioe131.com:~/fa18-BioE131/lab07/`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A priori, doyou expect to achieve better or worse compressionhere than random data?   Why? \n",
    "Should be better than the random data as the 10 homologs are to ~90 similarities with each other, and so there're much more repeated patterns recurring for efficient algorirhm to compress the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compress the multi-FASTAusing gzip, bzip2, and arithmetic coding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gp120.fa\n",
      "0.00user 0.00system 0:00.00elapsed 75%CPU (0avgtext+0avgdata 1712maxresident)k\n",
      "0inputs+16outputs (0major+114minor)pagefaults 0swaps\n",
      "\n",
      "0.00user 0.00system 0:00.00elapsed 85%CPU (0avgtext+0avgdata 1908maxresident)k\n",
      "0inputs+16outputs (0major+196minor)pagefaults 0swaps\n",
      "\n",
      "0.01user 0.00system 0:00.01elapsed 100%CPU (0avgtext+0avgdata 4304maxresident)k\n",
      "0inputs+24outputs (0major+237minor)pagefaults 0swaps\n",
      "\n",
      "gp120.fa\n",
      "7300\n",
      "7044\n",
      "9699\n",
      "28280\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "\n",
    "file_names = [\"gp120.fa\"]\n",
    "gzip_time = []\n",
    "bzip_time = []\n",
    "arith_time = []\n",
    "\n",
    "for file_name in file_names:\n",
    "    print(file_name)\n",
    "    arith_out_name = file_name + \".art\"\n",
    "    pdbzip_name = file_name+ \"b\"\n",
    "    p1 = subprocess.run(['time', 'gzip', '-k', file_name], stdout=subprocess.PIPE, stderr= subprocess.PIPE)\n",
    "    out1 = p1.stderr.decode()\n",
    "    print(out1)\n",
    "    gzip_time.append(str(out1))\n",
    "    \n",
    "    p2 = subprocess.run(['time', 'bzip2', '-k', file_name], stdout=subprocess.PIPE, stderr= subprocess.PIPE)\n",
    "    out2 = p2.stderr.decode()\n",
    "    print(out2)\n",
    "    bzip_time.append(str(out2))\n",
    "    \n",
    "    p4 = subprocess.run(['time',\"ArithmeticCompress\",file_name,arith_out_name], stdout=subprocess.PIPE, stderr= subprocess.PIPE)\n",
    "    out4 = p4.stderr.decode()\n",
    "    print(out4)\n",
    "    arith_time.append(str(out4))\n",
    "\n",
    "\n",
    "original_size = []\n",
    "gzip_size = []\n",
    "bzip_size = []\n",
    "arith_size = []\n",
    "\n",
    "for file_name in file_names:\n",
    "    print(file_name)\n",
    "    arith_out_name = file_name + \".art\"\n",
    "    bzip_name = file_name+ \".bz2\"\n",
    "    gzip_name = file_name+ \".gz\"\n",
    "    \n",
    "    p1 = subprocess.run(['stat', '--printf=%s', gzip_name], stdout=subprocess.PIPE, stderr= subprocess.PIPE)\n",
    "    out1 = p1.stdout.decode()\n",
    "    print(out1)\n",
    "    gzip_size.append(str(out1))\n",
    "    \n",
    "    p2 = subprocess.run(['stat', '--printf=%s', bzip_name], stdout=subprocess.PIPE, stderr= subprocess.PIPE)\n",
    "    out2 = p2.stdout.decode()\n",
    "    print(out2)\n",
    "    bzip_size.append(str(out2))\n",
    "    \n",
    "    p4 = subprocess.run(['stat', '--printf=%s', arith_out_name], stdout=subprocess.PIPE, stderr= subprocess.PIPE)\n",
    "    out4 = p4.stdout.decode()\n",
    "    print(out4)\n",
    "    arith_size.append(str(out4))\n",
    "    \n",
    "    p5 = subprocess.run(['stat', '--printf=%s', file_name], stdout=subprocess.PIPE, stderr= subprocess.PIPE)\n",
    "    out5 = p5.stdout.decode()\n",
    "    print(out5)\n",
    "    original_size.append(str(out5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>original_size</th>\n",
       "      <th>gzip_ratio</th>\n",
       "      <th>bzip_ratio</th>\n",
       "      <th>arith_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gp120.fa</td>\n",
       "      <td>28280</td>\n",
       "      <td>0.258133</td>\n",
       "      <td>0.249081</td>\n",
       "      <td>0.342963</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   filename original_size  gzip_ratio  bzip_ratio  arith_ratio\n",
       "0  gp120.fa         28280    0.258133    0.249081     0.342963"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "gzip_ratio = np.divide([int(i) for i in gzip_size], [int(i) for i in original_size])\n",
    "bzip_ratio = np.divide([int(i) for i in bzip_size], [int(i) for i in original_size])\n",
    "arith_ratio = np.divide([int(i) for i in arith_size], [int(i) for i in original_size])\n",
    "\n",
    "d = {'filename': file_names, 'original_size': original_size,'gzip_ratio':gzip_ratio,'bzip_ratio':bzip_ratio,'arith_ratio':arith_ratio}\n",
    "df = pd.DataFrame(data=d)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Discussion\n",
    "Estimating compression of 1000 terabytes\n",
    "Let’s make some assumptions about the contents of the data at your biotech company. Most of the data, say 80%, is re-sequencing of genomes and plasmids that are very similar to each other. Another 10% might be protein sequences, and the last 10% are binary microscope images which we’ll assume follow the worst-case scenario of being completely random. Given the benchmarking data you obtained in this lab, which algorithm do you propose to use for each type of data? Provide an estimate for the fraction of space you can save using your compression scheme. How much of a bonus do you anticipate receiving this year?\n",
    "\n",
    "As demonstrated by our various sequences with high-0 concentrations (which can be extrapolated to represent highly similar sequences), the __pbzip__ method is the fastest and yields files that are comparable in size after compression (final size is about 55% of the original file size). Because of the parallelization involved in pbzip, we expect that the difference in time from compressing the data will be negligible, and so we can still produce 1000 terabytes of data a day. However, with compression we expect to save 45% of the storage space with each file (1000 terabytes-> 550 terabytes). This 45% times 500 dollars per percent saved = 22500 dollars saved per day. This is __8.213 million dollars__ in savings per year (assuming this much data is generated all 365 days of the year). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
